# 새로 알게된 것

## 회귀분석

- 관찰된 여러 데이터를 기반으로 각 연속형 변수 간의 관계를 모델링하고 이에 대한 적합도를 측정하는 분석 방법
- 독립변수(설명변수)와 종속변수(반응변수) 사이의 상호 관련성을 규명하는 것들

ex) 아버지의 키 x와 자식의 키 y사이의 직선 형태의 기울기가 1보다 작다.

→ 세대를 거듭할수록 아버지의 키가 크든 작든 무관하게 자식의 키는 전체 평균에 수렴하게 된다.

→ 통계적으로 **회귀** 한다.

→ 오늘날은 단순히 평균으로 수렴하는 현상을 넘어 두 개 이상의 변수 사이의 함수관계를 추구하는 통계적인 방법을 의미

### 선형 회귀분석의 기본 가정

- 선형성, 독립성, 등분산성, 정규성

### 선형 회귀 모델링

$$y = Bx + c$$

- B는 회귀계수, c는 오차
- 선형회귀 모델을 찾는다는 것은 선형식이 잘 맞도록 B와 c를 구하는 것

### 머신러닝에서 선형 회귀 모델

$$y = Wx + b$$

- W는 가중치,  b는 편향

### 최소제곱법

- 잔차들 제곱의 합을 최소로 하는 W,b를 구하는 것
- 머신러닝에서는 손실함수라고 부름

### Sigmoid 함수

$$a = 1/(1 + exp(-z))$$

- 사건이 발생할 확률 /  사건이 발생하지 않을 확률인 odds에서 유도됨
- z=0인 지점을 중심으로 하여 두 범주 간 경계가 불명확해지는 x의 구간(0.3 < p < 0.7)을 최소화해주기 때문에 분류모델 성능을 매우 향상시켜줌

### Logistic 회귀

- 분류 모델일 것 같지만 회귀 모델
- 분류에 사용하는 것은 범주별 확률 값을 계산하는 로지스틱 회귀의 특성을 활용한 것.
- 이진 분류만이 아니라 여러 범주로 분류하는 다중 로지스틱 회귀로 확장될 수 있다.

### Softmax

- 2가지가 아닌 여러 범주로 분류하는 함수
- 큰 log-odds와 작은 log-odds 차이를 극대화시켜줌
- 가장 큰 값을 1, 그 외 나머지 값을 0으로 인코딩하는 원핫 인코딩을 통해 표현

### Cross entropy

- softmax의 손실함수
- 로지스틱 회귀모델이 추론한 확률 분포와 실제 데이터의 분포의 차이를 계산

# 더 궁금한 것