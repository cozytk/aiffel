{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 준비: (64, 4, 2)\n",
      "1단계 연산 결과: (64, 4)\n",
      "1단계 Linear Layer의 Weight 형태: (2, 1)\n",
      "\n",
      "2단계 연산 준비: (64, 4)\n",
      "2단계 연산 결과: (64,)\n",
      "2단계 Linear Layer의 Weight 형태: (4, 1)\n",
      "1단계 연산 준비: (64, 4, 2)\n",
      "1단계 연산 결과: (64, 4)\n",
      "1단계 Linear Layer의 Weight 형태: (2, 1)\n",
      "\n",
      "2단계 연산 준비: (64, 4)\n",
      "2단계 연산 결과: (64,)\n",
      "2단계 Linear Layer의 Weight 형태: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))     # Tensorflow는 Batch를 기반으로 동작하기에,\n",
    "                                         # 우리는 사각형 2개 세트를 batch_size개만큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(64, 4, 2), dtype=float32, numpy=\narray([[[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]]], dtype=float32)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 준비: (64, 4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(64, 4, 1), dtype=float32, numpy=\narray([[[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                         # 만든 후 처리를 하게 됩니다.\n",
    "print(\"1단계 연산 준비:\", boxes.shape)\n",
    "\n",
    "first_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "# units은 출력 차원 수를 의미합니다.\n",
    "# Weight 행렬 속 실수를 인간의 뇌 속 하나의 뉴런 '유닛' 취급을 하는 거죠!\n",
    "\n",
    "first_out = first_linear(boxes)\n",
    "first_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(64, 4), dtype=float32, numpy=\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]], dtype=float32)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_out = tf.squeeze(first_out, axis=-1) # (4, 1)을 (4,)로 변환해줍니다.\n",
    "first_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 결과: (64, 4)\n",
      "1단계 Linear Layer의 Weight 형태: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "                                           # (불필요한 차원 축소)\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2단계 연산 준비: (64, 4)\n",
      "2단계 연산 결과: (64,)\n",
      "2단계 Linear Layer의 Weight 형태: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2단계 연산 준비:\", first_out.shape)\n",
    "\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 준비: (64, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))\n",
    "\n",
    "print(\"1단계 연산 준비:\", boxes.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 결과: (64, 4, 3)\n",
      "1단계 Linear Layer의 Weight 형태: (2, 3)\n",
      "\n",
      "2단계 연산 준비: (64, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Step 1: (4,2)차원인 boxes를 (4,3)으로 확장시키는 Linear Layer를 활용하세요.\n",
    "\n",
    "first_linear = tf.keras.layers.Dense(units=3, use_bias=False)\n",
    "first_out = first_linear(boxes)\n",
    "\n",
    "########\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n2단계 연산 준비:\", first_out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2단계 연산 결과: (64, 4)\n",
      "2단계 Linear Layer의 Weight 형태: (3, 1)\n",
      "\n",
      "3단계 연산 준비: (64, 4)\n"
     ]
    }
   ],
   "source": [
    "# Dense = Linear\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n3단계 연산 준비:\", second_out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3단계 연산 결과: (64, 1)\n",
      "3단계 Linear Layer의 Weight 형태: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Step 2: 4차원인 second_out을 하나의 실수으로 집약시키는 Linear Layer를 활용하세요.\n",
    "\n",
    "third_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "third_out = third_linear(second_out)\n",
    "\n",
    "########\n",
    "\n",
    "print(\"3단계 연산 결과:\", third_out.shape)\n",
    "print(\"3단계 Linear Layer의 Weight 형태:\", third_linear.weights[0].shape)\n",
    "\n",
    "########"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Parameters: 13\n"
     ]
    }
   ],
   "source": [
    "# Step 3: 모든 params를 더하여 total_parmams를 구하세요.\n",
    "\n",
    "total_params = (first_linear.count_params() + second_linear.count_params() +\n",
    "                third_linear.count_params())\n",
    "\n",
    "########\n",
    "\n",
    "print(\"총 Parameters:\", total_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}